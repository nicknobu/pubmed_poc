# services/evaluation.py ã«ãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½ã‚’è¿½åŠ ã—ãŸç‰ˆ

import numpy as np
import openai
import os
import re
from typing import Dict, Optional

class SummaryEvaluator:
    """è¦ç´„å“è³ªè©•ä¾¡ã‚¯ãƒ©ã‚¹ï¼ˆãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½ä»˜ãï¼‰"""
    
    def __init__(self, debug_mode=False):
        """OpenAI APIã‚­ãƒ¼ã®è¨­å®š"""
        self.api_key = os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        self.client = openai.OpenAI(api_key=self.api_key)
        self.debug_mode = debug_mode
    
def evaluate_summary_quality(self, original_text: str, summary: str) -> Dict:
    """å¤šè¨€èªå¯¾å¿œã®å“è³ªè©•ä¾¡ï¼ˆç·Šæ€¥ä¿®æ­£ç‰ˆï¼‰"""
    try:
        # 1. AbstractæŠ½å‡º
        abstract = self.extract_abstract_with_debug(original_text) if self.debug_mode else self.extract_abstract(original_text)
        
        if not abstract or len(abstract.strip()) < 50:
            return self._create_error_result("AbstractãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹çŸ­ã™ãã¾ã™")
        
        # 2. è¦ç´„ã®å‰å‡¦ç†
        processed_summary = self.preprocess_summary(summary)
        
        if not processed_summary or len(processed_summary.strip()) < 30:
            return self._create_error_result("è¦ç´„ãŒçŸ­ã™ãã‚‹ã‹ç„¡åŠ¹ã§ã™")
        
        # ğŸ†• 3. è¨€èªãƒšã‚¢æ¤œå‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
        is_multilingual = self._detect_multilingual_pair(abstract, processed_summary)
        
        # 4. ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
        cosine_similarity = self.calculate_cosine_similarity(abstract, processed_summary)
        
        # 5. æ”¹è‰¯ã•ã‚ŒãŸå“è³ªæŒ‡æ¨™
        word_overlap = self.calculate_multilingual_word_overlap(abstract, processed_summary)
        content_coverage = self.calculate_multilingual_content_coverage(abstract, processed_summary)
        
        # ğŸ†• 6. å¤šè¨€èªå¯¾å¿œã®è©•ä¾¡åŸºæº–
        if is_multilingual:
            # è‹±æ—¥é–“ã®ç¾å®Ÿçš„åŸºæº–
            cosine_threshold = 0.50  # 0.8 â†’ 0.50
            cosine_excellent = 0.65  # 0.85 â†’ 0.65
            quality_level = self._get_multilingual_quality_level(cosine_similarity)
            feedback = self._generate_multilingual_feedback(cosine_similarity, word_overlap, content_coverage)
            
            # èª¿æ•´æ¸ˆã¿ç·åˆã‚¹ã‚³ã‚¢ï¼ˆæ¦‚å¿µã‚«ãƒãƒ¼ç‡ã‚’é‡è¦–ï¼‰
            overall_score = (cosine_similarity * 0.45 + 
                           word_overlap * 0.15 + 
                           content_coverage * 0.40)
        else:
            # åŒè¨€èªé–“ã®å¾“æ¥åŸºæº–
            cosine_threshold = 0.80
            cosine_excellent = 0.85
            quality_level = self._get_quality_level(cosine_similarity)
            feedback = self._generate_feedback(cosine_similarity, word_overlap, content_coverage)
            
            overall_score = (cosine_similarity * 0.6 + 
                           word_overlap * 0.25 + 
                           content_coverage * 0.15)
        
        # 7. åˆæ ¼åˆ¤å®š
        pass_threshold = cosine_similarity >= cosine_threshold
        
        return {
            "success": True,
            "abstract_text": abstract[:300] + "..." if len(abstract) > 300 else abstract,
            "full_abstract": abstract,
            "summary_text": processed_summary,
            "cosine_similarity": round(cosine_similarity, 3),
            "word_overlap": round(word_overlap, 3),
            "content_coverage": round(content_coverage, 3),
            "overall_score": round(overall_score, 3),
            "pass_threshold": pass_threshold,
            "quality_level": quality_level,
            "feedback": feedback,
            "is_multilingual": is_multilingual,
            "evaluation_note": "è‹±æ—¥é–“è©•ä¾¡åŸºæº–é©ç”¨" if is_multilingual else "åŒè¨€èªé–“è©•ä¾¡åŸºæº–é©ç”¨",
            "debug_info": self._get_debug_info(original_text) if self.debug_mode else None
        }
        
    except Exception as e:
        return self._create_error_result(f"è©•ä¾¡å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")

def _detect_multilingual_pair(self, text1: str, text2: str) -> bool:
    """å¤šè¨€èªãƒšã‚¢ã‹ã©ã†ã‹ã‚’æ¤œå‡º"""
    # è‹±èªã®ç‰¹å¾´çš„æ–‡å­—ã®æ¯”ç‡
    english_chars1 = len([c for c in text1 if c.isascii() and c.isalpha()])
    total_chars1 = len([c for c in text1 if c.isalpha()])
    english_ratio1 = english_chars1 / total_chars1 if total_chars1 > 0 else 0
    
    # æ—¥æœ¬èªã®ç‰¹å¾´çš„æ–‡å­—ã®å­˜åœ¨
    japanese_chars2 = len([c for c in text2 if 0x3040 <= ord(c) <= 0x30FF or 0x4E00 <= ord(c) <= 0x9FAF])
    japanese_ratio2 = japanese_chars2 / len(text2) if len(text2) > 0 else 0
    
    # è‹±èªAbstract + æ—¥æœ¬èªè¦ç´„ã®çµ„ã¿åˆã‚ã›ã‚’æ¤œå‡º
    return english_ratio1 > 0.8 and japanese_ratio2 > 0.1

def calculate_multilingual_word_overlap(self, text1: str, text2: str) -> float:
    """å¤šè¨€èªå¯¾å¿œã®å˜èªé‡è¤‡ç‡ï¼ˆæ¦‚å¿µãƒ¬ãƒ™ãƒ«ï¼‰"""
    # åŸºæœ¬çš„ãªåŒ»å­¦æ¦‚å¿µã®è‹±æ—¥å¯¾å¿œ
    medical_concepts = {
        'osteoporosis': 'éª¨ç²—é¬†ç—‡',
        'parathyroid': 'å‰¯ç”²çŠ¶è…º',
        'hormone': 'ãƒ›ãƒ«ãƒ¢ãƒ³',
        'treatment': 'æ²»ç™‚',
        'compliance': 'éµå®ˆ',
        'patients': 'æ‚£è€…',
        'fracture': 'éª¨æŠ˜',
        'medication': 'è–¬ç‰©',
        'therapy': 'ç™‚æ³•',
        'clinical': 'è‡¨åºŠ',
        'study': 'ç ”ç©¶',
        'retrospective': 'å¾Œã‚å‘ã',
        'prospective': 'å‰å‘ã',
        'months': 'ãƒ¶æœˆ',
        'years': 'å¹´',
        'risk': 'ãƒªã‚¹ã‚¯'
    }
    
    # æ¦‚å¿µãƒ¬ãƒ™ãƒ«ã§ã®ä¸€è‡´ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    concept_matches = 0
    total_concepts = len(medical_concepts)
    
    for en_word, ja_word in medical_concepts.items():
        if en_word.lower() in text1.lower() and ja_word in text2:
            concept_matches += 1
    
    # åŸºæœ¬çš„ãªå˜èªé‡è¤‡ã‚‚è€ƒæ…®
    basic_overlap = super().calculate_word_overlap(text1, text2)
    
    # æ¦‚å¿µä¸€è‡´ç‡ã¨åŸºæœ¬é‡è¤‡ç‡ã®çµ„ã¿åˆã‚ã›
    concept_score = concept_matches / total_concepts if total_concepts > 0 else 0
    combined_score = (concept_score * 0.7) + (basic_overlap * 0.3)
    
    return min(combined_score, 1.0)

def calculate_multilingual_content_coverage(self, abstract: str, summary: str) -> float:
    """å¤šè¨€èªå¯¾å¿œã®é‡è¦æ¦‚å¿µã‚«ãƒãƒ¼ç‡"""
    # è‹±èªãƒ‘ã‚¿ãƒ¼ãƒ³
    english_patterns = [
        r'\b\d+(?:\.\d+)?%',  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸
        r'\bp\s*[<>=]\s*0\.\d+',  # på€¤
        r'\b\d+(?:\.\d+)?\s*(?:months?|years?|days?)',  # æœŸé–“
        r'\b\d+(?:\.\d+)?\s*(?:mg|g|ml|patients?|cases?)',  # æ•°é‡ãƒ»å¯¾è±¡
    ]
    
    # æ—¥æœ¬èªãƒ‘ã‚¿ãƒ¼ãƒ³
    japanese_patterns = [
        r'\d+(?:\.\d+)?%',  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸
        r'\d+(?:\.\d+)?(?:ãƒ¶?æœˆ|å¹´|æ—¥)',  # æœŸé–“
        r'\d+(?:\.\d+)?(?:å|äºº|ä¾‹|ä»¶)',  # å¯¾è±¡æ•°
        r'\d+(?:\.\d+)?å€',  # å€ç‡
        r'p\s*[<>=]\s*0\.\d+',  # på€¤
    ]
    
    # è‹±èªAbstractä¸­ã®é‡è¦ãƒ‡ãƒ¼ã‚¿
    abstract_matches = set()
    for pattern in english_patterns:
        abstract_matches.update(re.findall(pattern, abstract.lower()))
    
    # æ—¥æœ¬èªè¦ç´„ä¸­ã®é‡è¦ãƒ‡ãƒ¼ã‚¿
    summary_matches = set()
    for pattern in japanese_patterns:
        summary_matches.update(re.findall(pattern, summary))
    
    # æ•°å€¤ã®éƒ¨åˆ†ä¸€è‡´ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆä¾‹ï¼š15.5 months â†’ 15.5ãƒ¶æœˆï¼‰
    abstract_numbers = set(re.findall(r'\d+(?:\.\d+)?', abstract))
    summary_numbers = set(re.findall(r'\d+(?:\.\d+)?', summary))
    
    number_overlap = len(abstract_numbers.intersection(summary_numbers))
    total_numbers = len(abstract_numbers)
    
    if total_numbers > 0:
        number_coverage = number_overlap / total_numbers
    else:
        number_coverage = 0.5
    
    # æ¦‚å¿µçš„é‡è¦åº¦ã‚‚è€ƒæ…®
    important_concepts_coverage = 0.0
    concept_pairs = [
        ('54%', '54%'), ('60%', '60%'), ('24-month', '24ãƒ¶æœˆ'),
        ('15.5 months', '15.5'), ('compliance', 'éµå®ˆ'),
        ('non-compliance', 'ééµå®ˆ'), ('retrospective', 'å¾Œã‚å‘ã')
    ]
    
    matched_concepts = 0
    for en_concept, ja_concept in concept_pairs:
        if en_concept.lower() in abstract.lower() and ja_concept in summary:
            matched_concepts += 1
    
    if concept_pairs:
        important_concepts_coverage = matched_concepts / len(concept_pairs)
    
    # ç·åˆã‚«ãƒãƒ¼ç‡
    final_coverage = (number_coverage * 0.6) + (important_concepts_coverage * 0.4)
    return min(final_coverage, 1.0)

def _get_multilingual_quality_level(self, cosine_sim: float) -> str:
    """å¤šè¨€èªé–“ã®å“è³ªãƒ¬ãƒ™ãƒ«åˆ¤å®š"""
    if cosine_sim >= 0.65:
        return "å„ªç§€"
    elif cosine_sim >= 0.55:
        return "è‰¯å¥½"
    elif cosine_sim >= 0.50:
        return "æ¨™æº–"
    elif cosine_sim >= 0.45:
        return "è¦æ”¹å–„"
    else:
        return "ä¸ååˆ†"

def _generate_multilingual_feedback(self, cosine_sim: float, word_overlap: float, coverage: float) -> str:
    """å¤šè¨€èªé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ"""
    feedback = []
    
    if cosine_sim >= 0.65:
        feedback.append("è‹±æ—¥é–“ç¿»è¨³ã¨ã—ã¦å„ªç§€ãªæ„å‘³çš„é¡ä¼¼åº¦ã‚’é”æˆã—ã¦ã„ã¾ã™")
    elif cosine_sim >= 0.55:
        feedback.append("è‹±æ—¥é–“ç¿»è¨³ã¨ã—ã¦è‰¯å¥½ãªæ„å‘³çš„é¡ä¼¼åº¦ã§ã™")
    elif cosine_sim >= 0.50:
        feedback.append("è‹±æ—¥é–“ç¿»è¨³ã¨ã—ã¦æ¨™æº–çš„ãªæ„å‘³çš„é¡ä¼¼åº¦ã§ã™")
    else:
        feedback.append("è‹±æ—¥é–“ç¿»è¨³ã®æ„å‘³çš„é¡ä¼¼åº¦ã®å‘ä¸ŠãŒæ¨å¥¨ã•ã‚Œã¾ã™")
    
    if word_overlap >= 0.15:
        feedback.append("åŒ»å­¦æ¦‚å¿µã®ç¿»è¨³ãŒé©åˆ‡ã«è¡Œã‚ã‚Œã¦ã„ã¾ã™")
    elif word_overlap < 0.10:
        feedback.append("è‹±æ—¥é–“ç¿»è¨³ã®ãŸã‚å˜èªé‡è¤‡ç‡ã¯è‡ªç„¶ã«ä½ããªã‚Šã¾ã™")
    
    if coverage >= 0.50:
        feedback.append("é‡è¦ãªæ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒé©åˆ‡ã«ä¿æŒã•ã‚Œã¦ã„ã¾ã™")
    elif coverage >= 0.30:
        feedback.append("æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ä¿æŒã¯æ¨™æº–çš„ã§ã™")
    else:
        feedback.append("é‡è¦ãªæ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ä¿æŒç‡å‘ä¸ŠãŒæ¨å¥¨ã•ã‚Œã¾ã™")
    
    return "ã€‚".join(feedback) if feedback else "è‹±æ—¥é–“ç¿»è¨³ã¨ã—ã¦é©åˆ‡ãªå“è³ªã§ã™"
    
    def extract_abstract_with_debug(self, text: str) -> Optional[str]:
        """ãƒ‡ãƒãƒƒã‚°æƒ…å ±ä»˜ãAbstractæŠ½å‡º"""
        lines = text.split('\n')
        
        if self.debug_mode:
            print(f"ğŸ” ãƒ†ã‚­ã‚¹ãƒˆã‚’{len(lines)}è¡Œã«åˆ†å‰²")
            print("ğŸ” æœ€åˆã®20è¡Œ:")
            for i, line in enumerate(lines[:20]):
                print(f"  {i+1:2d}: {line[:80]}")
            print()
        
        # Method 1: æ§‹é€ åŒ–Abstract
        abstract_sections = self._extract_structured_abstract_debug(lines)
        if abstract_sections:
            if self.debug_mode:
                print("âœ… æ§‹é€ åŒ–AbstractæŠ½å‡ºæˆåŠŸ")
            return abstract_sections
        
        if self.debug_mode:
            print("âŒ æ§‹é€ åŒ–AbstractæŠ½å‡ºå¤±æ•—")
        
        # Method 2: å¾“æ¥å‹Abstract
        abstract_content = self._extract_traditional_abstract_debug(lines)
        if abstract_content:
            if self.debug_mode:
                print("âœ… å¾“æ¥å‹AbstractæŠ½å‡ºæˆåŠŸ")
            return abstract_content
        
        if self.debug_mode:
            print("âŒ å¾“æ¥å‹AbstractæŠ½å‡ºå¤±æ•—")
        
        # Method 3: å†’é ­éƒ¨åˆ†æ¨å®š
        beginning_content = self._extract_from_beginning_debug(lines)
        if beginning_content:
            if self.debug_mode:
                print("âœ… å†’é ­éƒ¨åˆ†æ¨å®šæˆåŠŸ")
            return beginning_content
        
        if self.debug_mode:
            print("âŒ å…¨ã¦ã®æŠ½å‡ºæ–¹æ³•ãŒå¤±æ•—")
        
        return None
    
    def _extract_structured_abstract_debug(self, lines: list) -> Optional[str]:
        """æ§‹é€ åŒ–AbstractæŠ½å‡ºï¼ˆãƒ‡ãƒãƒƒã‚°ç‰ˆï¼‰"""
        abstract_parts = []
        current_section = None
        in_abstract_area = False
        found_sections = []
        
        for i, line in enumerate(lines):
            line_clean = line.strip()
            line_lower = line_clean.lower()
            
            # Abstracté ˜åŸŸã®é–‹å§‹ã‚’æ¤œå‡º
            if ('abstract' in line_lower and len(line_clean) < 50 and 
                not line_lower.startswith('background')):
                in_abstract_area = True
                if self.debug_mode:
                    print(f"ğŸ¯ Abstracté–‹å§‹æ¤œå‡º: è¡Œ{i+1}")
                continue
            
            # Backgroundä»¥é™ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¤œå‡º
            if in_abstract_area or any(section in line_lower for section in ['background', 'objective', 'purpose']):
                in_abstract_area = True
                
                # ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¦‹å‡ºã—ã®æ¤œå‡º
                if line_lower in ['background', 'methods', 'results', 'conclusion', 'conclusions']:
                    current_section = line_lower
                    found_sections.append(line_lower)
                    if self.debug_mode:
                        print(f"ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¤œå‡º: {line_lower} (è¡Œ{i+1})")
                    continue
                elif line_lower.startswith('background'):
                    current_section = 'background'
                    found_sections.append('background')
                    if self.debug_mode:
                        print(f"ğŸ“ Backgroundé–‹å§‹: è¡Œ{i+1}")
                    # è¦‹å‡ºã—è¡Œã«å†…å®¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆ
                    if len(line_clean) > 15:
                        content = line_clean.split(' ', 1)[1] if ' ' in line_clean else line_clean
                        if content and len(content) > 10:
                            abstract_parts.append(content)
                            if self.debug_mode:
                                print(f"  å†…å®¹è¿½åŠ : {content[:50]}...")
                    continue
                elif line_lower.startswith('method'):
                    current_section = 'methods'
                    found_sections.append('methods')
                    if self.debug_mode:
                        print(f"ğŸ“ Methodsé–‹å§‹: è¡Œ{i+1}")
                    continue
                elif line_lower.startswith('result'):
                    current_section = 'results'
                    found_sections.append('results')
                    if self.debug_mode:
                        print(f"ğŸ“ Resultsé–‹å§‹: è¡Œ{i+1}")
                    continue
                elif line_lower.startswith('conclusion'):
                    current_section = 'conclusion'
                    found_sections.append('conclusion')
                    if self.debug_mode:
                        print(f"ğŸ“ Conclusioné–‹å§‹: è¡Œ{i+1}")
                    continue
                
                # Abstractçµ‚äº†ã®åˆ¤å®š
                if (line_lower in ['keywords', 'keyword'] or 
                    line_lower.startswith('keywords:') or
                    line_lower.startswith('keyword:') or
                    any(keyword in line_lower for keyword in ['introduction', '## introduction', 'citation'])):
                    if self.debug_mode:
                        print(f"ğŸ›‘ Abstractçµ‚äº†æ¤œå‡º: è¡Œ{i+1} ({line_lower})")
                    break
                
                # å†…å®¹ã®è¿½åŠ 
                if current_section and line_clean and len(line_clean) > 10:
                    # ç®‡æ¡æ›¸ãã‚„ç•ªå·ã‚’é™¤å»
                    cleaned_line = re.sub(r'^[â€¢Â·-]\s*', '', line_clean)
                    cleaned_line = re.sub(r'^\d+[\.)]\s*', '', cleaned_line)
                    
                    if (cleaned_line and 
                        not cleaned_line.lower().startswith(('abstract', 'background', 'method', 'result', 'conclusion')) and
                        len(cleaned_line) > 5):
                        abstract_parts.append(cleaned_line)
                        if self.debug_mode:
                            print(f"  {current_section}å†…å®¹: {cleaned_line[:50]}...")
        
        if self.debug_mode:
            print(f"ğŸ” ç™ºè¦‹ã•ã‚ŒãŸã‚»ã‚¯ã‚·ãƒ§ãƒ³: {found_sections}")
            print(f"ğŸ” æŠ½å‡ºã•ã‚ŒãŸéƒ¨åˆ†æ•°: {len(abstract_parts)}")
            if abstract_parts:
                print(f"ğŸ” çµ±åˆé•·: {len(' '.join(abstract_parts))} æ–‡å­—")
        
        # ååˆ†ãªå†…å®¹ãŒæŠ½å‡ºã•ã‚ŒãŸå ´åˆã®ã¿è¿”ã™
        if abstract_parts and len(' '.join(abstract_parts)) > 200:
            return ' '.join(abstract_parts)
        
        return None
    
    def _extract_traditional_abstract_debug(self, lines: list) -> Optional[str]:
        """å¾“æ¥å‹AbstractæŠ½å‡ºï¼ˆãƒ‡ãƒãƒƒã‚°ç‰ˆï¼‰"""
        abstract_lines = []
        in_abstract = False
        abstract_start_line = -1
        
        for i, line in enumerate(lines):
            line_clean = line.strip()
            line_lower = line_clean.lower()
            
            # Abstracté–‹å§‹ã®åˆ¤å®š
            if ('abstract' in line_lower and len(line_clean) < 50):
                in_abstract = True
                abstract_start_line = i + 1
                if self.debug_mode:
                    print(f"ğŸ“ å¾“æ¥å‹Abstracté–‹å§‹: è¡Œ{i+1}")
                continue
            
            if in_abstract:
                # Abstractçµ‚äº†ã®åˆ¤å®š
                if (any(keyword in line_lower for keyword in 
                       ['introduction', 'keywords', '## ', 'citation', 'references']) and 
                    len(line_clean) < 100):
                    if self.debug_mode:
                        print(f"ğŸ›‘ å¾“æ¥å‹Abstractçµ‚äº†: è¡Œ{i+1}")
                    break
                
                # ç©ºè¡Œã¯ç„¡è¦–
                if not line_clean:
                    continue
                
                # æœ‰åŠ¹ãªå†…å®¹è¡Œã‚’è¿½åŠ 
                if len(line_clean) > 10:
                    abstract_lines.append(line_clean)
                    if self.debug_mode:
                        print(f"  å†…å®¹è¿½åŠ : {line_clean[:50]}...")
        
        if self.debug_mode:
            print(f"ğŸ” å¾“æ¥å‹æŠ½å‡ºçµæœ: {len(abstract_lines)}è¡Œ, {len(' '.join(abstract_lines))}æ–‡å­—")
        
        if abstract_lines and len(' '.join(abstract_lines)) > 100:
            return ' '.join(abstract_lines)
        
        return None
    
    def _extract_from_beginning_debug(self, lines: list) -> Optional[str]:
        """å†’é ­éƒ¨åˆ†æ¨å®šï¼ˆãƒ‡ãƒãƒƒã‚°ç‰ˆï¼‰"""
        early_lines = []
        
        for i, line in enumerate(lines[:30]):
            line_clean = line.strip()
            
            # ã‚¿ã‚¤ãƒˆãƒ«ã‚„ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if (len(line_clean) > 30 and 
                not line_clean.lower().startswith(('title:', 'author', 'doi:', 'pmid:'))):
                early_lines.append(line_clean)
                if self.debug_mode:
                    print(f"  å†’é ­éƒ¨åˆ†è¿½åŠ : {line_clean[:50]}...")
                
                # é©åº¦ãªé•·ã•ã§åˆ‡ã‚‹
                if len(' '.join(early_lines)) > 800:
                    break
        
        if self.debug_mode:
            print(f"ğŸ” å†’é ­éƒ¨åˆ†æ¨å®š: {len(early_lines)}è¡Œ, {len(' '.join(early_lines))}æ–‡å­—")
        
        if early_lines and len(' '.join(early_lines)) > 200:
            return ' '.join(early_lines)
        
        return None
    
    def _get_debug_info(self, text: str) -> Dict:
        """ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®åé›†"""
        lines = text.split('\n')
        return {
            "total_lines": len(lines),
            "total_chars": len(text),
            "first_20_lines": lines[:20],
            "lines_with_abstract": [i for i, line in enumerate(lines) if 'abstract' in line.lower()],
            "lines_with_background": [i for i, line in enumerate(lines) if 'background' in line.lower()],
            "lines_with_methods": [i for i, line in enumerate(lines) if 'method' in line.lower()],
            "lines_with_results": [i for i, line in enumerate(lines) if 'result' in line.lower()],
            "lines_with_conclusion": [i for i, line in enumerate(lines) if 'conclusion' in line.lower()],
        }
    
    # ãã®ä»–ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯å‰å›ã¨åŒã˜
    def preprocess_summary(self, summary: str) -> str:
        """3ç‚¹è¦ç´„ã‚’çµ±åˆã—ã¦ãƒ†ã‚­ã‚¹ãƒˆåŒ–"""
        cleaned = re.sub(r'^[0-9]+[.ï¼)]?\s*', '', summary, flags=re.MULTILINE)
        cleaned = re.sub(r'^[ãƒ»â—â—‹]\s*', '', cleaned, flags=re.MULTILINE)
        cleaned = re.sub(r'ã€[^ã€‘]*ã€‘', '', cleaned)
        cleaned = ' '.join(cleaned.split())
        return cleaned.strip()
    
    def calculate_cosine_similarity(self, text1: str, text2: str) -> float:
        """OpenAI Embeddingsã‚’ä½¿ç”¨ã—ãŸã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—"""
        try:
            text1_clean = text1[:8000]
            text2_clean = text2[:8000]
            
            response1 = self.client.embeddings.create(
                model="text-embedding-3-small",
                input=text1_clean,
                encoding_format="float"
            )
            
            response2 = self.client.embeddings.create(
                model="text-embedding-3-small",
                input=text2_clean,
                encoding_format="float"
            )
            
            vec1 = np.array(response1.data[0].embedding)
            vec2 = np.array(response2.data[0].embedding)
            
            dot_product = np.dot(vec1, vec2)
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            cosine_sim = dot_product / (norm1 * norm2)
            return float(cosine_sim)
            
        except Exception as e:
            print(f"ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def calculate_word_overlap(self, text1: str, text2: str) -> float:
        words1 = set(re.findall(r'\b\w+\b', text1.lower()))
        words2 = set(re.findall(r'\b\w+\b', text2.lower()))
        
        if len(words1) == 0 or len(words2) == 0:
            return 0.0
        
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        return intersection / union if union > 0 else 0.0
    
    def calculate_content_coverage(self, abstract: str, summary: str) -> float:
        important_patterns = [
            r'\b\d+(?:\.\d+)?%',
            r'\bp\s*[<>=]\s*0\.\d+',
            r'\b\d+(?:\.\d+)?\s*(?:months?|years?|days?)',
            r'\b\d+(?:\.\d+)?\s*(?:mg|g|ml|patients?|cases?)',
            r'\b(?:significant|effective|improvement|increase|decrease)\b',
        ]
        
        abstract_matches = set()
        summary_matches = set()
        
        for pattern in important_patterns:
            abstract_matches.update(re.findall(pattern, abstract.lower()))
            summary_matches.update(re.findall(pattern, summary.lower()))
        
        if len(abstract_matches) == 0:
            return 0.5
        
        coverage = len(summary_matches.intersection(abstract_matches)) / len(abstract_matches)
        return min(coverage, 1.0)
    
    def _calculate_overall_score(self, cosine_sim: float, word_overlap: float, coverage: float) -> float:
        weights = {'cosine': 0.6, 'overlap': 0.25, 'coverage': 0.15}
        return (cosine_sim * weights['cosine'] + 
                word_overlap * weights['overlap'] + 
                coverage * weights['coverage'])
    
    def _get_quality_level(self, score: float) -> str:
        if score >= 0.85:
            return "å„ªç§€"
        elif score >= 0.75:
            return "è‰¯å¥½"
        elif score >= 0.65:
            return "æ¨™æº–"
        elif score >= 0.50:
            return "è¦æ”¹å–„"
        else:
            return "ä¸ååˆ†"
    
    def _generate_feedback(self, cosine_sim: float, word_overlap: float, coverage: float) -> str:
        feedback = []
        
        if cosine_sim < 0.7:
            feedback.append("è¦ç´„å†…å®¹ãŒAbstractã¨å¤§ããç•°ãªã£ã¦ã„ã¾ã™")
        elif cosine_sim >= 0.8:
            feedback.append("è¦ç´„å†…å®¹ãŒAbstractã¨è‰¯ãä¸€è‡´ã—ã¦ã„ã¾ã™")
        
        if word_overlap < 0.3:
            feedback.append("é‡è¦ãªç”¨èªãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        
        if coverage < 0.3:
            feedback.append("æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚„é‡è¦æ¦‚å¿µã®è¨˜è¼‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
        elif coverage >= 0.6:
            feedback.append("é‡è¦ãªæ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒé©åˆ‡ã«å«ã¾ã‚Œã¦ã„ã¾ã™")
        
        return "ã€‚".join(feedback) if feedback else "è¦ç´„å“è³ªã¯æ¨™æº–çš„ã§ã™"
    
    def _create_error_result(self, error_message: str) -> Dict:
        return {
            "success": False,
            "error": error_message,
            "cosine_similarity": 0.0,
            "word_overlap": 0.0,
            "content_coverage": 0.0,
            "overall_score": 0.0,
            "pass_threshold": False,
            "quality_level": "ã‚¨ãƒ©ãƒ¼",
            "feedback": error_message
        }

# ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°
def evaluate_summary_debug(original_text: str, summary: str) -> Dict:
    """ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ä»˜ãè¦ç´„å“è³ªè©•ä¾¡"""
    evaluator = SummaryEvaluator(debug_mode=True)
    return evaluator.evaluate_summary_quality(original_text, summary)

def evaluate_summary(original_text: str, summary: str) -> Dict:
    """é€šå¸¸ã®è¦ç´„å“è³ªè©•ä¾¡"""
    evaluator = SummaryEvaluator(debug_mode=False)
    return evaluator.evaluate_summary_quality(original_text, summary)