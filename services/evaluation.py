# services/evaluation.py ã«ãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½ã‚’è¿½åŠ ã—ãŸç‰ˆ

import numpy as np
import openai
import os
import re
from typing import Dict, Optional

class SummaryEvaluator:
    """è¦ç´„å“è³ªè©•ä¾¡ã‚¯ãƒ©ã‚¹ï¼ˆãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½ä»˜ãï¼‰"""
    
    def __init__(self, debug_mode=False):
        """OpenAI APIã‚­ãƒ¼ã®è¨­å®š"""
        self.api_key = os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        self.client = openai.OpenAI(api_key=self.api_key)
        self.debug_mode = debug_mode
    
    def evaluate_summary_quality(self, original_text: str, summary: str) -> Dict:
        """è«–æ–‡Abstract vs è¦ç´„ã®å“è³ªè©•ä¾¡ï¼ˆãƒ‡ãƒãƒƒã‚°æƒ…å ±ä»˜ãï¼‰"""
        try:
            if self.debug_mode:
                print(f"ğŸ” å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(original_text)} æ–‡å­—")
                print(f"ğŸ” å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆæœ€åˆã®500æ–‡å­—:\n{original_text[:500]}\n")
            
            # 1. AbstractæŠ½å‡ºï¼ˆãƒ‡ãƒãƒƒã‚°æƒ…å ±ä»˜ãï¼‰
            abstract = self.extract_abstract_with_debug(original_text)
            
            if not abstract or len(abstract.strip()) < 50:
                return self._create_error_result("AbstractãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹çŸ­ã™ãã¾ã™")
            
            if self.debug_mode:
                print(f"âœ… AbstractæŠ½å‡ºæˆåŠŸ: {len(abstract)} æ–‡å­—")
                print(f"ğŸ“„ æŠ½å‡ºã•ã‚ŒãŸAbstract:\n{abstract[:300]}...\n")
            
            # 2. è¦ç´„ã®å‰å‡¦ç†
            processed_summary = self.preprocess_summary(summary)
            
            if not processed_summary or len(processed_summary.strip()) < 30:
                return self._create_error_result("è¦ç´„ãŒçŸ­ã™ãã‚‹ã‹ç„¡åŠ¹ã§ã™")
            
            # 3. ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
            cosine_similarity = self.calculate_cosine_similarity(abstract, processed_summary)
            
            # 4. è¿½åŠ ã®å“è³ªæŒ‡æ¨™
            word_overlap = self.calculate_word_overlap(abstract, processed_summary)
            content_coverage = self.calculate_content_coverage(abstract, processed_summary)
            
            # 5. ç·åˆè©•ä¾¡
            overall_score = self._calculate_overall_score(
                cosine_similarity, word_overlap, content_coverage
            )
            
            return {
                "success": True,
                "abstract_text": abstract[:300] + "..." if len(abstract) > 300 else abstract,
                "full_abstract": abstract,  # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šå®Œå…¨ãªAbstract
                "summary_text": processed_summary,
                "cosine_similarity": round(cosine_similarity, 3),
                "word_overlap": round(word_overlap, 3),
                "content_coverage": round(content_coverage, 3),
                "overall_score": round(overall_score, 3),
                "pass_threshold": cosine_similarity >= 0.8,
                "quality_level": self._get_quality_level(overall_score),
                "feedback": self._generate_feedback(cosine_similarity, word_overlap, content_coverage),
                "debug_info": self._get_debug_info(original_text) if self.debug_mode else None
            }
            
        except Exception as e:
            return self._create_error_result(f"è©•ä¾¡å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def extract_abstract_with_debug(self, text: str) -> Optional[str]:
        """ãƒ‡ãƒãƒƒã‚°æƒ…å ±ä»˜ãAbstractæŠ½å‡º"""
        lines = text.split('\n')
        
        if self.debug_mode:
            print(f"ğŸ” ãƒ†ã‚­ã‚¹ãƒˆã‚’{len(lines)}è¡Œã«åˆ†å‰²")
            print("ğŸ” æœ€åˆã®20è¡Œ:")
            for i, line in enumerate(lines[:20]):
                print(f"  {i+1:2d}: {line[:80]}")
            print()
        
        # Method 1: æ§‹é€ åŒ–Abstract
        abstract_sections = self._extract_structured_abstract_debug(lines)
        if abstract_sections:
            if self.debug_mode:
                print("âœ… æ§‹é€ åŒ–AbstractæŠ½å‡ºæˆåŠŸ")
            return abstract_sections
        
        if self.debug_mode:
            print("âŒ æ§‹é€ åŒ–AbstractæŠ½å‡ºå¤±æ•—")
        
        # Method 2: å¾“æ¥å‹Abstract
        abstract_content = self._extract_traditional_abstract_debug(lines)
        if abstract_content:
            if self.debug_mode:
                print("âœ… å¾“æ¥å‹AbstractæŠ½å‡ºæˆåŠŸ")
            return abstract_content
        
        if self.debug_mode:
            print("âŒ å¾“æ¥å‹AbstractæŠ½å‡ºå¤±æ•—")
        
        # Method 3: å†’é ­éƒ¨åˆ†æ¨å®š
        beginning_content = self._extract_from_beginning_debug(lines)
        if beginning_content:
            if self.debug_mode:
                print("âœ… å†’é ­éƒ¨åˆ†æ¨å®šæˆåŠŸ")
            return beginning_content
        
        if self.debug_mode:
            print("âŒ å…¨ã¦ã®æŠ½å‡ºæ–¹æ³•ãŒå¤±æ•—")
        
        return None
    
    def _extract_structured_abstract_debug(self, lines: list) -> Optional[str]:
        """æ§‹é€ åŒ–AbstractæŠ½å‡ºï¼ˆãƒ‡ãƒãƒƒã‚°ç‰ˆï¼‰"""
        abstract_parts = []
        current_section = None
        in_abstract_area = False
        found_sections = []
        
        for i, line in enumerate(lines):
            line_clean = line.strip()
            line_lower = line_clean.lower()
            
            # Abstracté ˜åŸŸã®é–‹å§‹ã‚’æ¤œå‡º
            if ('abstract' in line_lower and len(line_clean) < 50 and 
                not line_lower.startswith('background')):
                in_abstract_area = True
                if self.debug_mode:
                    print(f"ğŸ¯ Abstracté–‹å§‹æ¤œå‡º: è¡Œ{i+1}")
                continue
            
            # Backgroundä»¥é™ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¤œå‡º
            if in_abstract_area or any(section in line_lower for section in ['background', 'objective', 'purpose']):
                in_abstract_area = True
                
                # ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¦‹å‡ºã—ã®æ¤œå‡º
                if line_lower in ['background', 'methods', 'results', 'conclusion', 'conclusions']:
                    current_section = line_lower
                    found_sections.append(line_lower)
                    if self.debug_mode:
                        print(f"ğŸ“ ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¤œå‡º: {line_lower} (è¡Œ{i+1})")
                    continue
                elif line_lower.startswith('background'):
                    current_section = 'background'
                    found_sections.append('background')
                    if self.debug_mode:
                        print(f"ğŸ“ Backgroundé–‹å§‹: è¡Œ{i+1}")
                    # è¦‹å‡ºã—è¡Œã«å†…å®¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆ
                    if len(line_clean) > 15:
                        content = line_clean.split(' ', 1)[1] if ' ' in line_clean else line_clean
                        if content and len(content) > 10:
                            abstract_parts.append(content)
                            if self.debug_mode:
                                print(f"  å†…å®¹è¿½åŠ : {content[:50]}...")
                    continue
                elif line_lower.startswith('method'):
                    current_section = 'methods'
                    found_sections.append('methods')
                    if self.debug_mode:
                        print(f"ğŸ“ Methodsé–‹å§‹: è¡Œ{i+1}")
                    continue
                elif line_lower.startswith('result'):
                    current_section = 'results'
                    found_sections.append('results')
                    if self.debug_mode:
                        print(f"ğŸ“ Resultsé–‹å§‹: è¡Œ{i+1}")
                    continue
                elif line_lower.startswith('conclusion'):
                    current_section = 'conclusion'
                    found_sections.append('conclusion')
                    if self.debug_mode:
                        print(f"ğŸ“ Conclusioné–‹å§‹: è¡Œ{i+1}")
                    continue
                
                # Abstractçµ‚äº†ã®åˆ¤å®š
                if (line_lower in ['keywords', 'keyword'] or 
                    line_lower.startswith('keywords:') or
                    line_lower.startswith('keyword:') or
                    any(keyword in line_lower for keyword in ['introduction', '## introduction', 'citation'])):
                    if self.debug_mode:
                        print(f"ğŸ›‘ Abstractçµ‚äº†æ¤œå‡º: è¡Œ{i+1} ({line_lower})")
                    break
                
                # å†…å®¹ã®è¿½åŠ 
                if current_section and line_clean and len(line_clean) > 10:
                    # ç®‡æ¡æ›¸ãã‚„ç•ªå·ã‚’é™¤å»
                    cleaned_line = re.sub(r'^[â€¢Â·-]\s*', '', line_clean)
                    cleaned_line = re.sub(r'^\d+[\.)]\s*', '', cleaned_line)
                    
                    if (cleaned_line and 
                        not cleaned_line.lower().startswith(('abstract', 'background', 'method', 'result', 'conclusion')) and
                        len(cleaned_line) > 5):
                        abstract_parts.append(cleaned_line)
                        if self.debug_mode:
                            print(f"  {current_section}å†…å®¹: {cleaned_line[:50]}...")
        
        if self.debug_mode:
            print(f"ğŸ” ç™ºè¦‹ã•ã‚ŒãŸã‚»ã‚¯ã‚·ãƒ§ãƒ³: {found_sections}")
            print(f"ğŸ” æŠ½å‡ºã•ã‚ŒãŸéƒ¨åˆ†æ•°: {len(abstract_parts)}")
            if abstract_parts:
                print(f"ğŸ” çµ±åˆé•·: {len(' '.join(abstract_parts))} æ–‡å­—")
        
        # ååˆ†ãªå†…å®¹ãŒæŠ½å‡ºã•ã‚ŒãŸå ´åˆã®ã¿è¿”ã™
        if abstract_parts and len(' '.join(abstract_parts)) > 200:
            return ' '.join(abstract_parts)
        
        return None
    
    def _extract_traditional_abstract_debug(self, lines: list) -> Optional[str]:
        """å¾“æ¥å‹AbstractæŠ½å‡ºï¼ˆãƒ‡ãƒãƒƒã‚°ç‰ˆï¼‰"""
        abstract_lines = []
        in_abstract = False
        abstract_start_line = -1
        
        for i, line in enumerate(lines):
            line_clean = line.strip()
            line_lower = line_clean.lower()
            
            # Abstracté–‹å§‹ã®åˆ¤å®š
            if ('abstract' in line_lower and len(line_clean) < 50):
                in_abstract = True
                abstract_start_line = i + 1
                if self.debug_mode:
                    print(f"ğŸ“ å¾“æ¥å‹Abstracté–‹å§‹: è¡Œ{i+1}")
                continue
            
            if in_abstract:
                # Abstractçµ‚äº†ã®åˆ¤å®š
                if (any(keyword in line_lower for keyword in 
                       ['introduction', 'keywords', '## ', 'citation', 'references']) and 
                    len(line_clean) < 100):
                    if self.debug_mode:
                        print(f"ğŸ›‘ å¾“æ¥å‹Abstractçµ‚äº†: è¡Œ{i+1}")
                    break
                
                # ç©ºè¡Œã¯ç„¡è¦–
                if not line_clean:
                    continue
                
                # æœ‰åŠ¹ãªå†…å®¹è¡Œã‚’è¿½åŠ 
                if len(line_clean) > 10:
                    abstract_lines.append(line_clean)
                    if self.debug_mode:
                        print(f"  å†…å®¹è¿½åŠ : {line_clean[:50]}...")
        
        if self.debug_mode:
            print(f"ğŸ” å¾“æ¥å‹æŠ½å‡ºçµæœ: {len(abstract_lines)}è¡Œ, {len(' '.join(abstract_lines))}æ–‡å­—")
        
        if abstract_lines and len(' '.join(abstract_lines)) > 100:
            return ' '.join(abstract_lines)
        
        return None
    
    def _extract_from_beginning_debug(self, lines: list) -> Optional[str]:
        """å†’é ­éƒ¨åˆ†æ¨å®šï¼ˆãƒ‡ãƒãƒƒã‚°ç‰ˆï¼‰"""
        early_lines = []
        
        for i, line in enumerate(lines[:30]):
            line_clean = line.strip()
            
            # ã‚¿ã‚¤ãƒˆãƒ«ã‚„ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if (len(line_clean) > 30 and 
                not line_clean.lower().startswith(('title:', 'author', 'doi:', 'pmid:'))):
                early_lines.append(line_clean)
                if self.debug_mode:
                    print(f"  å†’é ­éƒ¨åˆ†è¿½åŠ : {line_clean[:50]}...")
                
                # é©åº¦ãªé•·ã•ã§åˆ‡ã‚‹
                if len(' '.join(early_lines)) > 800:
                    break
        
        if self.debug_mode:
            print(f"ğŸ” å†’é ­éƒ¨åˆ†æ¨å®š: {len(early_lines)}è¡Œ, {len(' '.join(early_lines))}æ–‡å­—")
        
        if early_lines and len(' '.join(early_lines)) > 200:
            return ' '.join(early_lines)
        
        return None
    
    def _get_debug_info(self, text: str) -> Dict:
        """ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®åé›†"""
        lines = text.split('\n')
        return {
            "total_lines": len(lines),
            "total_chars": len(text),
            "first_20_lines": lines[:20],
            "lines_with_abstract": [i for i, line in enumerate(lines) if 'abstract' in line.lower()],
            "lines_with_background": [i for i, line in enumerate(lines) if 'background' in line.lower()],
            "lines_with_methods": [i for i, line in enumerate(lines) if 'method' in line.lower()],
            "lines_with_results": [i for i, line in enumerate(lines) if 'result' in line.lower()],
            "lines_with_conclusion": [i for i, line in enumerate(lines) if 'conclusion' in line.lower()],
        }
    
    # ãã®ä»–ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯å‰å›ã¨åŒã˜
    def preprocess_summary(self, summary: str) -> str:
        """3ç‚¹è¦ç´„ã‚’çµ±åˆã—ã¦ãƒ†ã‚­ã‚¹ãƒˆåŒ–"""
        cleaned = re.sub(r'^[0-9]+[.ï¼)]?\s*', '', summary, flags=re.MULTILINE)
        cleaned = re.sub(r'^[ãƒ»â—â—‹]\s*', '', cleaned, flags=re.MULTILINE)
        cleaned = re.sub(r'ã€[^ã€‘]*ã€‘', '', cleaned)
        cleaned = ' '.join(cleaned.split())
        return cleaned.strip()
    
    def calculate_cosine_similarity(self, text1: str, text2: str) -> float:
        """OpenAI Embeddingsã‚’ä½¿ç”¨ã—ãŸã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—"""
        try:
            text1_clean = text1[:8000]
            text2_clean = text2[:8000]
            
            response1 = self.client.embeddings.create(
                model="text-embedding-3-small",
                input=text1_clean,
                encoding_format="float"
            )
            
            response2 = self.client.embeddings.create(
                model="text-embedding-3-small",
                input=text2_clean,
                encoding_format="float"
            )
            
            vec1 = np.array(response1.data[0].embedding)
            vec2 = np.array(response2.data[0].embedding)
            
            dot_product = np.dot(vec1, vec2)
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            cosine_sim = dot_product / (norm1 * norm2)
            return float(cosine_sim)
            
        except Exception as e:
            print(f"ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def calculate_word_overlap(self, text1: str, text2: str) -> float:
        words1 = set(re.findall(r'\b\w+\b', text1.lower()))
        words2 = set(re.findall(r'\b\w+\b', text2.lower()))
        
        if len(words1) == 0 or len(words2) == 0:
            return 0.0
        
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        return intersection / union if union > 0 else 0.0
    
    def calculate_content_coverage(self, abstract: str, summary: str) -> float:
        important_patterns = [
            r'\b\d+(?:\.\d+)?%',
            r'\bp\s*[<>=]\s*0\.\d+',
            r'\b\d+(?:\.\d+)?\s*(?:months?|years?|days?)',
            r'\b\d+(?:\.\d+)?\s*(?:mg|g|ml|patients?|cases?)',
            r'\b(?:significant|effective|improvement|increase|decrease)\b',
        ]
        
        abstract_matches = set()
        summary_matches = set()
        
        for pattern in important_patterns:
            abstract_matches.update(re.findall(pattern, abstract.lower()))
            summary_matches.update(re.findall(pattern, summary.lower()))
        
        if len(abstract_matches) == 0:
            return 0.5
        
        coverage = len(summary_matches.intersection(abstract_matches)) / len(abstract_matches)
        return min(coverage, 1.0)
    
    def _calculate_overall_score(self, cosine_sim: float, word_overlap: float, coverage: float) -> float:
        weights = {'cosine': 0.6, 'overlap': 0.25, 'coverage': 0.15}
        return (cosine_sim * weights['cosine'] + 
                word_overlap * weights['overlap'] + 
                coverage * weights['coverage'])
    
    def _get_quality_level(self, score: float) -> str:
        if score >= 0.85:
            return "å„ªç§€"
        elif score >= 0.75:
            return "è‰¯å¥½"
        elif score >= 0.65:
            return "æ¨™æº–"
        elif score >= 0.50:
            return "è¦æ”¹å–„"
        else:
            return "ä¸ååˆ†"
    
    def _generate_feedback(self, cosine_sim: float, word_overlap: float, coverage: float) -> str:
        feedback = []
        
        if cosine_sim < 0.7:
            feedback.append("è¦ç´„å†…å®¹ãŒAbstractã¨å¤§ããç•°ãªã£ã¦ã„ã¾ã™")
        elif cosine_sim >= 0.8:
            feedback.append("è¦ç´„å†…å®¹ãŒAbstractã¨è‰¯ãä¸€è‡´ã—ã¦ã„ã¾ã™")
        
        if word_overlap < 0.3:
            feedback.append("é‡è¦ãªç”¨èªãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        
        if coverage < 0.3:
            feedback.append("æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚„é‡è¦æ¦‚å¿µã®è¨˜è¼‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
        elif coverage >= 0.6:
            feedback.append("é‡è¦ãªæ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒé©åˆ‡ã«å«ã¾ã‚Œã¦ã„ã¾ã™")
        
        return "ã€‚".join(feedback) if feedback else "è¦ç´„å“è³ªã¯æ¨™æº–çš„ã§ã™"
    
    def _create_error_result(self, error_message: str) -> Dict:
        return {
            "success": False,
            "error": error_message,
            "cosine_similarity": 0.0,
            "word_overlap": 0.0,
            "content_coverage": 0.0,
            "overall_score": 0.0,
            "pass_threshold": False,
            "quality_level": "ã‚¨ãƒ©ãƒ¼",
            "feedback": error_message
        }

# ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°
def evaluate_summary_debug(original_text: str, summary: str) -> Dict:
    """ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ä»˜ãè¦ç´„å“è³ªè©•ä¾¡"""
    evaluator = SummaryEvaluator(debug_mode=True)
    return evaluator.evaluate_summary_quality(original_text, summary)

def evaluate_summary(original_text: str, summary: str) -> Dict:
    """é€šå¸¸ã®è¦ç´„å“è³ªè©•ä¾¡"""
    evaluator = SummaryEvaluator(debug_mode=False)
    return evaluator.evaluate_summary_quality(original_text, summary)